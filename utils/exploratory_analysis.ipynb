{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b74dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils import load_nli_data\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "\n",
    "spacy.prefer_gpu()\n",
    "exclude_pipelines = [\n",
    "    \"parser\",\n",
    "    \"tagger\",\n",
    "    \"ner\",\n",
    "    \"textcat\",\n",
    "    \"lemmatizer\",\n",
    "    \"attribute_ruler\",\n",
    "    \"tok2vec\",\n",
    "]\n",
    "\n",
    "nlp = spacy.load(\n",
    "    \"en_core_web_lg\",\n",
    "    exclude=exclude_pipelines,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe4856",
   "metadata": {},
   "outputs": [],
   "source": [
    "snli = load_nli_data(\"../data/snli_1.0_test.jsonl\")\n",
    "\n",
    "snli.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaca329",
   "metadata": {},
   "source": [
    "# 1- Token Size Analysis per Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838b8a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use spaCy's batch processing to get token counts efficiently\n",
    "print(\"Processing sentences to get token counts...\")\n",
    "\n",
    "# Process premises\n",
    "docs1 = list(\n",
    "    tqdm(\n",
    "        nlp.pipe(snli[\"sentence1\"].tolist(), batch_size=128, n_process=-1),\n",
    "        desc=\"Processing sentence1\",\n",
    "        total=len(snli),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Process hypotheses\n",
    "docs2 = list(\n",
    "    tqdm(\n",
    "        nlp.pipe(snli[\"sentence2\"].tolist(), batch_size=128, n_process=-1),\n",
    "        desc=\"Processing sentence2\",\n",
    "        total=len(snli),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add token counts to dataframe\n",
    "snli[\"sentence1_token_count\"] = [len(doc) for doc in docs1]\n",
    "snli[\"sentence2_token_count\"] = [len(doc) for doc in docs2]\n",
    "\n",
    "# Display summary statistics\n",
    "token_stats = snli.groupby(\"gold_label\")[\n",
    "    [\"sentence1_token_count\", \"sentence2_token_count\"]\n",
    "].describe()\n",
    "\n",
    "# Create a more readable summary table\n",
    "summary = pd.DataFrame()\n",
    "for label in snli[\"gold_label\"].unique():\n",
    "    label_data = snli[snli[\"gold_label\"] == label]\n",
    "    for col in [\"sentence1_token_count\", \"sentence2_token_count\"]:\n",
    "        col_name = \"Premise\" if col == \"sentence1_token_count\" else \"Hypothesis\"\n",
    "        stats = label_data[col].describe()\n",
    "        summary = pd.concat(\n",
    "            [\n",
    "                summary,\n",
    "                pd.DataFrame(\n",
    "                    {\n",
    "                        \"Label\": label,\n",
    "                        \"Type\": col_name,\n",
    "                        \"Mean\": stats[\"mean\"],\n",
    "                        \"Std\": stats[\"std\"],\n",
    "                        \"Min\": stats[\"min\"],\n",
    "                        \"Max\": stats[\"max\"],\n",
    "                    },\n",
    "                    index=[0],\n",
    "                ),\n",
    "            ],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "\n",
    "# Display the cleaner summary table\n",
    "display(\n",
    "    summary.pivot(index=\"Label\", columns=\"Type\")[[\"Mean\", \"Std\", \"Min\", \"Max\"]]\n",
    "    .style.background_gradient(cmap=\"viridis\")\n",
    "    .set_caption(\"Token Count Statistics by Label\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b645c652",
   "metadata": {},
   "source": [
    "* Create box plots for each label to visualize the distribution of token sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40435211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations for token count distributions\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot token count distributions by label\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x=\"gold_label\", y=\"sentence1_token_count\", data=snli)\n",
    "plt.title(\"Premise Token Counts by Label\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Token Count\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x=\"gold_label\", y=\"sentence2_token_count\", data=snli)\n",
    "plt.title(\"Hypothesis Token Counts by Label\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Token Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"data/token_counts_by_label.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0925f4e8",
   "metadata": {},
   "source": [
    "# 2-Similarity Analysis per Label\n",
    "* This function aims to compute the similarity of each label in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce19f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses Spacy's en_core_web_lg embeddings model for NLP pipeline\n",
    "# and computes the similarity between sentence1 and sentence2\n",
    "# using the vectors of the sentences.\n",
    "# The similarity is computed using the cosine similarity of the vectors\n",
    "\n",
    "docs1 = list(\n",
    "    tqdm(\n",
    "        nlp.pipe(snli[\"sentence1\"].tolist(), batch_size=128, n_process=-1),\n",
    "        desc=\"Processing sentence1\",\n",
    "        total=len(snli),\n",
    "    )\n",
    ")\n",
    "\n",
    "docs2 = list(\n",
    "    tqdm(\n",
    "        nlp.pipe(snli[\"sentence2\"].tolist(), batch_size=128, n_process=-1),\n",
    "        desc=\"Processing sentence2\",\n",
    "        total=len(snli),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Compute similarities using vectors\n",
    "snli[\"similarity\"] = [\n",
    "    doc1.similarity(doc2)\n",
    "    for doc1, doc2 in tqdm(\n",
    "        zip(docs1, docs2), desc=\"Computing similarities\", total=len(snli)\n",
    "    )\n",
    "]\n",
    "\n",
    "snli.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aa264a",
   "metadata": {},
   "source": [
    "* Boxplot is used to visualize the distribution of similarity scores for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98d40c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplot\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=\"gold_label\", y=\"similarity\", data=snli)\n",
    "plt.title(\"Similarity Scores by NLI Label\")\n",
    "plt.xlabel(\"Label\")\n",
    "plt.ylabel(\"Cosine Similarity\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "plt.savefig(\"data/similarity_by_label.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db908617",
   "metadata": {},
   "source": [
    "* Histogram is used to visualize the distribution of similarity scores across all labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6089e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histograms with KDE\n",
    "plt.figure(figsize=(12, 6))\n",
    "for label, color in zip(\n",
    "    [\"entailment\", \"contradiction\", \"neutral\"], [\"#66b3ff\", \"#ff9999\", \"#99ff99\"]\n",
    "):\n",
    "    subset = snli[snli[\"gold_label\"] == label]\n",
    "    sns.histplot(\n",
    "        subset[\"similarity\"], label=label, alpha=0.6, color=color, bins=30, kde=True\n",
    "    )\n",
    "\n",
    "plt.title(\"Distribution of Similarity Scores by Label\")\n",
    "plt.xlabel(\"Similarity Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "plt.savefig(\"similarity_distributions.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69306df8",
   "metadata": {},
   "source": [
    "# 3- Lexical Overlap per label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e0e9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_overlap_by_label(\n",
    "    df, text_col1=\"sentence1\", text_col2=\"sentence2\", label_col=\"gold_label\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Analyzes the lexical overlap between pairs of text using Jaccard similarity.\n",
    "    \n",
    "    This function computes the Jaccard similarity coefficient between the token sets\n",
    "    of two text columns, grouped by a label column. Jaccard similarity measures the\n",
    "    size of the intersection divided by the size of the union of two sets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing the text columns and label column\n",
    "    text_col1 : str, default=\"sentence1\"\n",
    "        Column name for the first text (premise in NLI tasks)\n",
    "    text_col2 : str, default=\"sentence2\"\n",
    "        Column name for the second text (hypothesis in NLI tasks)\n",
    "    label_col : str, default=\"gold_label\"\n",
    "        Column name for the labels\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        DataFrame containing the label and jaccard similarity scores\n",
    "        \n",
    "    Notes:\n",
    "    ------\n",
    "    Higher Jaccard scores indicate greater word overlap between the texts.\n",
    "    In NLI tasks, this can reveal patterns like entailment pairs having \n",
    "    higher lexical overlap than contradiction pairs.\n",
    "    \"\"\"\n",
    "    overlaps, labels = [], []\n",
    "    for s1, s2, lbl in tqdm(\n",
    "        zip(df[text_col1], df[text_col2], df[label_col]),\n",
    "        total=len(df),\n",
    "        desc=\"Lexical Overlap\",\n",
    "    ):\n",
    "        d1, d2 = nlp(s1), nlp(s2)\n",
    "        t1 = {tok.text.lower() for tok in d1}\n",
    "        t2 = {tok.text.lower() for tok in d2}\n",
    "        score = len(t1 & t2) / len(t1 | t2) if t1 | t2 else 0.0\n",
    "        overlaps.append(score)\n",
    "        labels.append(lbl)\n",
    "\n",
    "    out = pd.DataFrame({label_col: labels, \"jaccard\": overlaps})\n",
    "    # summary stats\n",
    "    display(out.groupby(label_col)[\"jaccard\"].describe().T)\n",
    "    # boxplot\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(x=label_col, y=\"jaccard\", data=out)\n",
    "    plt.title(\"Lexical Overlap (Jaccard) by Label\")\n",
    "    plt.show()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a4bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_overlap_by_label(snli)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2fb47d",
   "metadata": {},
   "source": [
    "# 4-Embeddings Space Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6868ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_tsne_pairwise_by_label(\n",
    "    df,\n",
    "    text_cols=(\"sentence1\", \"sentence2\"),\n",
    "    label_col=\"gold_label\",\n",
    "    batch_size=128,\n",
    "    random_state=42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize sentence pairs in embedding space using t-SNE dimensionality reduction.\n",
    "    \n",
    "    This function creates relationship vectors that capture the semantic connection between \n",
    "    sentence pairs, then projects them to 2D space for visualization. For each sentence pair, \n",
    "    a composite vector is created by concatenating:\n",
    "      - The premise vector (v1)\n",
    "      - The hypothesis vector (v2) \n",
    "      - The absolute difference between vectors (|v1-v2|)\n",
    "      - The element-wise product of vectors (v1*v2)\n",
    "    \n",
    "    This rich representation captures both the individual sentence semantics and their relationship,\n",
    "    which is useful for natural language inference tasks.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame containing text pairs and labels\n",
    "    text_cols : tuple of str, default=(\"sentence1\", \"sentence2\")\n",
    "        Column names for the text pairs to compare\n",
    "    label_col : str, default=\"gold_label\"\n",
    "        Column name for the categorical labels\n",
    "    batch_size : int, default=128\n",
    "        Batch size for efficient document processing\n",
    "    random_state : int, default=42\n",
    "        Random seed for t-SNE to ensure reproducibility\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        Displays a scatter plot of the sentence pair embeddings projected to 2D space\n",
    "        \n",
    "    Notes:\n",
    "    ------\n",
    "    The composite representation approach is inspired by InferSent (Conneau et al., 2017)\n",
    "    and helps the model capture relationships between text pairs rather than just \n",
    "    individual sentence meanings.\n",
    "    \"\"\"\n",
    "    docs1 = list(\n",
    "        tqdm(\n",
    "            nlp.pipe(df[text_cols[0]].tolist(), batch_size=batch_size, n_process=-1),\n",
    "            total=len(df),\n",
    "            desc=f\"Encoding {text_cols[0]}\",\n",
    "        )\n",
    "    )\n",
    "    docs2 = list(\n",
    "        tqdm(\n",
    "            nlp.pipe(df[text_cols[1]].tolist(), batch_size=batch_size, n_process=-1),\n",
    "            total=len(df),\n",
    "            desc=f\"Encoding {text_cols[1]}\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    rel_vecs = []\n",
    "    for d1, d2 in zip(docs1, docs2):\n",
    "        v1 = d1.vector\n",
    "        v2 = d2.vector\n",
    "        rel = np.concatenate(\n",
    "            [\n",
    "                v1,  # premise\n",
    "                v2,  # hypothesis\n",
    "                np.abs(v1 - v2),  # difference\n",
    "                v1 * v2,  # elementwise product\n",
    "            ]\n",
    "        )\n",
    "        rel_vecs.append(rel)\n",
    "    X = np.vstack(rel_vecs)  # shape (n_pairs, 4*vector_dim)\n",
    "\n",
    "    if isinstance(X, cp.ndarray):\n",
    "        X = cp.asnumpy(X)\n",
    "\n",
    "    labels = df[label_col].values\n",
    "\n",
    "    X2d = TSNE(\n",
    "        n_components=2,\n",
    "        random_state=random_state,\n",
    "        init=\"random\",  # often helps reproducibility\n",
    "        learning_rate=\"auto\",\n",
    "    ).fit_transform(X)\n",
    "\n",
    "    emb_df = pd.DataFrame({\"x\": X2d[:, 0], \"y\": X2d[:, 1], label_col: labels})\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.scatterplot(\n",
    "        data=emb_df, x=\"x\", y=\"y\", hue=label_col, palette=\"tab10\", s=15, alpha=0.7\n",
    "    )\n",
    "    plt.title(\"t-SNE of spaCy Relationship Embeddings\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3315c965",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_tsne_pairwise_by_label(snli)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contradiction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
