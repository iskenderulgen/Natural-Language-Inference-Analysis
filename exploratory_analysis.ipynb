{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b74dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils import load_nli_data\n",
    "\n",
    "spacy.prefer_gpu()\n",
    "exclude_pipelines = [\n",
    "    \"parser\",\n",
    "    \"tagger\",\n",
    "    \"ner\",\n",
    "    \"textcat\",\n",
    "    \"lemmatizer\",\n",
    "    \"attribute_ruler\",\n",
    "    \"tok2vec\",\n",
    "]\n",
    "\n",
    "nlp = spacy.load(\n",
    "    \"en_core_web_lg\",\n",
    "    exclude=exclude_pipelines,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fe4856",
   "metadata": {},
   "outputs": [],
   "source": [
    "snli = load_nli_data(\"data/snli_1.0_dev.jsonl\")\n",
    "\n",
    "snli.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaca329",
   "metadata": {},
   "source": [
    "# 1- Token Size Analysis per Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838b8a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use spaCy's batch processing to get token counts efficiently\n",
    "print(\"Processing sentences to get token counts...\")\n",
    "\n",
    "# Process premises\n",
    "docs1 = list(\n",
    "    tqdm(\n",
    "        nlp.pipe(snli[\"sentence1\"].tolist(), batch_size=128, n_process=-1),\n",
    "        desc=\"Processing sentence1\",\n",
    "        total=len(snli),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Process hypotheses\n",
    "docs2 = list(\n",
    "    tqdm(\n",
    "        nlp.pipe(snli[\"sentence2\"].tolist(), batch_size=128, n_process=-1),\n",
    "        desc=\"Processing sentence2\",\n",
    "        total=len(snli),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add token counts to dataframe\n",
    "snli[\"sentence1_token_count\"] = [len(doc) for doc in docs1]\n",
    "snli[\"sentence2_token_count\"] = [len(doc) for doc in docs2]\n",
    "\n",
    "# Display summary statistics\n",
    "token_stats = snli.groupby(\"gold_label\")[[\"sentence1_token_count\", \"sentence2_token_count\"]].describe()\n",
    "\n",
    "# Create a more readable summary table\n",
    "summary = pd.DataFrame()\n",
    "for label in snli['gold_label'].unique():\n",
    "    label_data = snli[snli['gold_label'] == label]\n",
    "    for col in ['sentence1_token_count', 'sentence2_token_count']:\n",
    "        col_name = 'Premise' if col == 'sentence1_token_count' else 'Hypothesis'\n",
    "        stats = label_data[col].describe()\n",
    "        summary = pd.concat([summary, pd.DataFrame({\n",
    "            'Label': label,\n",
    "            'Type': col_name,\n",
    "            'Mean': stats['mean'],\n",
    "            'Std': stats['std'],\n",
    "            'Min': stats['min'],\n",
    "            'Max': stats['max'],\n",
    "        }, index=[0])], ignore_index=True)\n",
    "\n",
    "# Display the cleaner summary table\n",
    "display(summary.pivot(index='Label', columns='Type')[['Mean', 'Std', 'Min', 'Max']].style\n",
    "        .background_gradient(cmap=\"viridis\")\n",
    "        .set_caption(\"Token Count Statistics by Label\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b645c652",
   "metadata": {},
   "source": [
    "* Create box plots for each label to visualize the distribution of token sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40435211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations for token count distributions\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot token count distributions by label\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x='gold_label', y='sentence1_token_count', data=snli)\n",
    "plt.title('Premise Token Counts by Label')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Token Count')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x='gold_label', y='sentence2_token_count', data=snli)\n",
    "plt.title('Hypothesis Token Counts by Label')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Token Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('data/token_counts_by_label.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0925f4e8",
   "metadata": {},
   "source": [
    "# 2-Similarity Analysis per Label\n",
    "* This function aims to compute the similarity of each label in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce19f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses Spacy's en_core_web_lg embeddings model for NLP pipeline\n",
    "# and computes the similarity between sentence1 and sentence2\n",
    "# using the vectors of the sentences.\n",
    "# The similarity is computed using the cosine similarity of the vectors\n",
    "\n",
    "docs1 = list(\n",
    "    tqdm(\n",
    "        nlp.pipe(snli[\"sentence1\"].tolist(), batch_size=128, n_process=-1),\n",
    "        desc=\"Processing sentence1\",\n",
    "        total=len(snli),\n",
    "    )\n",
    ")\n",
    "\n",
    "docs2 = list(\n",
    "    tqdm(\n",
    "        nlp.pipe(snli[\"sentence2\"].tolist(), batch_size=128, n_process=-1),\n",
    "        desc=\"Processing sentence2\",\n",
    "        total=len(snli),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Compute similarities using vectors\n",
    "snli[\"similarity\"] = [\n",
    "    doc1.similarity(doc2)\n",
    "    for doc1, doc2 in tqdm(\n",
    "        zip(docs1, docs2), desc=\"Computing similarities\", total=len(snli)\n",
    "    )\n",
    "]\n",
    "\n",
    "snli.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aa264a",
   "metadata": {},
   "source": [
    "* Boxplot is used to visualize the distribution of similarity scores for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98d40c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boxplot\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='gold_label', y='similarity', data=snli)\n",
    "plt.title('Similarity Scores by NLI Label')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Cosine Similarity')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.savefig('data/similarity_by_label.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db908617",
   "metadata": {},
   "source": [
    "* Histogram is used to visualize the distribution of similarity scores across all labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6089e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create histograms with KDE\n",
    "plt.figure(figsize=(12, 6))\n",
    "for label, color in zip(['entailment', 'contradiction', 'neutral'], \n",
    "                        ['#66b3ff', '#ff9999', '#99ff99']):\n",
    "    subset = snli[snli['gold_label'] == label]\n",
    "    sns.histplot(subset['similarity'], label=label, \n",
    "                alpha=0.6, color=color, bins=30, kde=True)\n",
    "\n",
    "plt.title('Distribution of Similarity Scores by Label')\n",
    "plt.xlabel('Similarity Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.savefig('similarity_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13421b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contradiction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
