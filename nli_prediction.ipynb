{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58db4bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "\n",
    "from utils import (\n",
    "    tokenize_to_ids,\n",
    ")\n",
    "\n",
    "nlp = spacy.load(\n",
    "    \"en_core_web_lg\",\n",
    "    exclude=[\n",
    "        \"parser\",\n",
    "        \"tagger\",\n",
    "        \"ner\",\n",
    "        \"textcat\",\n",
    "        \"lemmatizer\",\n",
    "        \"attribute_ruler\",\n",
    "        \"tok2vec\",\n",
    "    ],\n",
    ")\n",
    "print(\"unique vector size\", len(nlp.vocab.vectors))\n",
    "\n",
    "# Hyper‑parameters\n",
    "MAX_LEN = 64\n",
    "NUM_CLASSES = 3\n",
    "NR_UNK = 100\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "label_map = {\"entailment\": 0, \"contradiction\": 1, \"neutral\": 2}\n",
    "\n",
    "# reverse it: id→name\n",
    "id2label = {v: k for k, v in label_map.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4e24d4",
   "metadata": {},
   "source": [
    "# ESIM Model NLI Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf57f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_and_plot(model, text1: str, text2: str):\n",
    "    \"\"\"Run inference & show both Premise→Hypothesis and Hypothesis→Premise attention.\"\"\"\n",
    "    # 1) Tokenize → ids → tensors\n",
    "    ids1 = tokenize_to_ids([text1], nlp, MAX_LEN, NR_UNK)\n",
    "    ids2 = tokenize_to_ids([text2], nlp, MAX_LEN, NR_UNK)\n",
    "    x1 = torch.tensor(ids1, device=device)\n",
    "    x2 = torch.tensor(ids2, device=device)\n",
    "    l1 = (x1 != 0).sum(1)\n",
    "    l2 = (x2 != 0).sum(1)\n",
    "\n",
    "    # 2) Forward pass w/ attention\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits, (att_p2h, att_h2p) = model(x1, l1, x2, l2, return_attention=True)\n",
    "        probs = F.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "\n",
    "    pred = probs.argmax()\n",
    "    print(f\"Prediction: {id2label[pred]}\")\n",
    "    print(\n",
    "        \"Scores: \"\n",
    "        + \", \".join(f\"{id2label[i]}={probs[i]:.3f}\" for i in range(len(probs)))\n",
    "    )\n",
    "\n",
    "    # 3) Extract tokens\n",
    "    toks1 = [t.text for t in list(nlp(text1))[: l1.item()]]\n",
    "    toks2 = [t.text for t in list(nlp(text2))[: l2.item()]]\n",
    "\n",
    "    # 4) Plot both attentions side‑by‑side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Premise → Hypothesis\n",
    "    A1 = att_p2h[0, : len(toks1), : len(toks2)].cpu().numpy()\n",
    "    sns.heatmap(\n",
    "        A1,\n",
    "        ax=axes[0],\n",
    "        xticklabels=toks2,\n",
    "        yticklabels=toks1,\n",
    "        cmap=\"viridis\",\n",
    "        cbar_kws={\"label\": \"attention\"},\n",
    "        fmt=\".2f\",\n",
    "    )\n",
    "    axes[0].set_title(\"Premise → Hypothesis\")\n",
    "    axes[0].set_xlabel(\"Hypothesis tokens\")\n",
    "    axes[0].set_ylabel(\"Premise tokens\")\n",
    "    axes[0].tick_params(axis=\"x\", rotation=45)\n",
    "    axes[0].tick_params(axis=\"y\", rotation=0)\n",
    "\n",
    "    # Hypothesis → Premise\n",
    "    A2 = att_h2p[0, : len(toks2), : len(toks1)].cpu().numpy()\n",
    "    sns.heatmap(\n",
    "        A2,\n",
    "        ax=axes[1],\n",
    "        xticklabels=toks1,\n",
    "        yticklabels=toks2,\n",
    "        cmap=\"magma\",\n",
    "        cbar_kws={\"label\": \"attention\"},\n",
    "        fmt=\".2f\",\n",
    "    )\n",
    "    axes[1].set_title(\"Hypothesis → Premise\")\n",
    "    axes[1].set_xlabel(\"Premise tokens\")\n",
    "    axes[1].set_ylabel(\"Hypothesis tokens\")\n",
    "    axes[1].tick_params(axis=\"x\", rotation=45)\n",
    "    axes[1].tick_params(axis=\"y\", rotation=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe06b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"data/esim_nli_model.pt\", map_location=device, weights_only=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a4ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "premise = \"in the park alice plays a flute solo\"\n",
    "hypothesis = \"someone playing music outside\"\n",
    "\n",
    "infer_and_plot(model, premise, hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad055e0",
   "metadata": {},
   "source": [
    "# BERT Model NLI Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97505003",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"data/checkpoints/bert-snli\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"data/checkpoints/bert-snli\",\n",
    "    output_attentions=True,\n",
    "    attn_implementation=\"eager\",\n",
    "    output_hidden_states=True,\n",
    ").to(device)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56156c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare your sentence pair\n",
    "premise = \"in the park alice plays a flute solo\"\n",
    "hypothesis = \"someone playing music outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a082991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize for classification\n",
    "inputs = tokenizer(\n",
    "    premise,\n",
    "    hypothesis,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors=\"pt\",\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ffd901",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    probs = torch.softmax(outputs.logits, dim=-1)[0].cpu().numpy()\n",
    "attentions = outputs.attentions  # tuple of (layers) x (batch, heads, L, L)\n",
    "\n",
    "pred = int(probs.argmax())\n",
    "print(f\"Prediction: {id2label[pred]}\")\n",
    "\n",
    "print(\n",
    "    \"Scores: \" + \", \".join(f\"{id2label[i]}={probs[i]:.3f}\" for i in range(len(probs)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden = outputs.hidden_states[-1][0]  # shape (seq_len, hidden_dim)\n",
    "\n",
    "# Find token indices for premise & hypothesis (skip [CLS], [SEP], [PAD])\n",
    "ids = inputs[\"input_ids\"][0].cpu().tolist()\n",
    "sep_id = tokenizer.sep_token_id\n",
    "sep_positions = [i for i, tok in enumerate(ids) if tok == sep_id]\n",
    "premise_idx = list(range(1, sep_positions[0]))\n",
    "hypo_idx = list(range(sep_positions[0] + 1, sep_positions[1]))\n",
    "\n",
    "# Slice embeddings\n",
    "P = last_hidden[premise_idx]  # (Lp, D)\n",
    "H = last_hidden[hypo_idx]  # (Lh, D)\n",
    "\n",
    "# Compute raw similarity matrix & normalize like ESIM\n",
    "sim_matrix = torch.matmul(P, H.T)  # (Lp, Lh)\n",
    "attn_p2h = F.softmax(sim_matrix, dim=1)  # premise→hypo rows sum to 1\n",
    "attn_h2p = F.softmax(sim_matrix.T, dim=1)  # hypo→premise rows sum to 1\n",
    "\n",
    "# Convert IDs → tokens\n",
    "premise_tokens = tokenizer.convert_ids_to_tokens([ids[i] for i in premise_idx])\n",
    "hypothesis_tokens = tokenizer.convert_ids_to_tokens([ids[i] for i in hypo_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab22c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot side-by-side like ESIM\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Premise → Hypothesis\n",
    "sns.heatmap(\n",
    "    attn_p2h.cpu().numpy(),\n",
    "    ax=axes[0],\n",
    "    xticklabels=hypothesis_tokens,\n",
    "    yticklabels=premise_tokens,\n",
    "    cmap=\"viridis\",\n",
    "    cbar_kws={\"label\": \"attention\"},\n",
    "    fmt=\".2f\",\n",
    ")\n",
    "axes[0].set_title(\"Premise → Hypothesis\")\n",
    "axes[0].set_xlabel(\"Hypothesis tokens\")\n",
    "axes[0].set_ylabel(\"Premise tokens\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=45)\n",
    "plt.setp(axes[0].get_xticklabels(), ha=\"right\")\n",
    "axes[0].tick_params(axis=\"y\", rotation=0)\n",
    "\n",
    "# Hypothesis → Premise\n",
    "sns.heatmap(\n",
    "    attn_h2p.cpu().numpy(),\n",
    "    ax=axes[1],\n",
    "    xticklabels=premise_tokens,\n",
    "    yticklabels=hypothesis_tokens,\n",
    "    cmap=\"magma\",\n",
    "    cbar_kws={\"label\": \"attention\"},\n",
    "    fmt=\".2f\",\n",
    ")\n",
    "axes[1].set_title(\"Hypothesis → Premise\")\n",
    "axes[1].set_xlabel(\"Premise tokens\")\n",
    "axes[1].set_ylabel(\"Hypothesis tokens\")\n",
    "axes[1].tick_params(axis=\"x\", rotation=45)\n",
    "plt.setp(axes[1].get_xticklabels(), ha=\"right\")\n",
    "axes[1].tick_params(axis=\"y\", rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contradiction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
